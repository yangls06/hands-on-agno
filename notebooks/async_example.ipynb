
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Async Response Handling in Jupyter\n",
    "\n",
    "This notebook demonstrates how to handle async responses in Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-async",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "# Enable nested asyncio in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"Async setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-async",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic async function example\n",
    "async def fetch_data_async(delay=2):\n",
    "    print(f\"Starting async operation (will take {delay} seconds)...\")\n",
    "    await asyncio.sleep(delay)\n",
    "    return f\"Async operation completed after {delay} seconds!\"\n",
    "\n",
    "# Run async function in notebook\n",
    "result = await fetch_data_async(3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "http-async",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async HTTP request example\n",
    "async def fetch_url_async(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            print(f\"Fetching {url}...\")\n",
    "            async with session.get(url) as response:\n",
    "                data = await response.text()\n",
    "                return {\n",
    "                    'status': response.status,\n",
    "                    'length': len(data),\n",
    "                    'url': url\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {'error': str(e), 'url': url}\n",
    "\n",
    "# Test with a simple API\n",
    "result = await fetch_url_async('https://httpbin.org/json')\n",
    "print(f\"Response: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-async",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple async operations concurrently\n",
    "async def fetch_multiple_urls():\n",
    "    urls = [\n",
    "        'https://httpbin.org/delay/1',\n",
    "        'https://httpbin.org/delay/2',\n",
    "        'https://httpbin.org/delay/1'\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run all requests concurrently\n",
    "    tasks = [fetch_url_async(url) for url in urls]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Completed {len(urls)} requests in {end_time - start_time:.2f} seconds\")\n",
    "    return results\n",
    "\n",
    "# Execute multiple async operations\n",
    "results = await fetch_multiple_urls()\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Request {i+1}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "openai-async",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with OpenAI API (async)\n",
    "import os\n",
    "import json\n",
    "\n",
    "async def call_openai_async(prompt, api_key=None):\n",
    "    if not api_key:\n",
    "        api_key = os.environ.get('OPENAI_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        return {'error': 'No OpenAI API key found'}\n",
    "    \n",
    "    url = 'https://api.openai.com/v1/chat/completions'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'messages': [{'role': 'user', 'content': prompt}],\n",
    "        'max_tokens': 100\n",
    "    }\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.post(url, headers=headers, json=data) as response:\n",
    "                result = await response.json()\n",
    "                if response.status == 200:\n",
    "                    return result['choices'][0]['message']['content']\n",
    "                else:\n",
    "                    return {'error': result}\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "\n",
    "# Test OpenAI async call\n",
    "openai_response = await call_openai_async(\"Say hello in a creative way\")\n",
    "print(f\"OpenAI Response: {openai_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-async",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating streaming responses\n",
    "async def simulate_streaming_response():\n",
    "    \"\"\"Simulate a streaming response like from an LLM\"\"\"\n",
    "    words = [\"Hello\", \"there!\", \"This\", \"is\", \"a\", \"streaming\", \"response\", \"simulation.\"]\n",
    "    \n",
    "    full_response = \"\"\n",
    "    for word in words:\n",
    "        await asyncio.sleep(0.5)  # Simulate delay\n",
    "        full_response += word + \" \"\n",
    "        print(f\"\\rCurrent response: {full_response.strip()}\", end=\"\")\n",
    "    \n",
    "    print(\"\\nStreaming complete!\")\n",
    "    return full_response.strip()\n",
    "\n",
    "# Run streaming simulation\n",
    "final_response = await simulate_streaming_response()\n",
    "print(f\"Final response: {final_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
